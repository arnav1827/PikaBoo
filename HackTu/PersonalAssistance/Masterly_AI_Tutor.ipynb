{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "da9a1dc1-05bb-4d45-8f83-ea6cf1dd3674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\gradio\\components\\chatbot.py:282: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7903\n",
      "* Running on public URL: https://5243ff82125e7ddbab.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5243ff82125e7ddbab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import ollama \n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# AI Tutor System Prompt\n",
    "system_prompt = \"\"\"\n",
    "You are **Masterly AI Tutor**, a 24/7 instant doubt-clearing assistant specialized in helping students prepare for master‚Äôs entrance exams.\n",
    "Your task is to provide **accurate, clear, and concise answers** to user queries, focusing on the master‚Äôs exam syllabus, concepts, problem-solving\n",
    "techniques, and past exam patterns.\n",
    "\n",
    "### **Instructions for Response Generation:**\n",
    "- **Accuracy & Clarity:** Deliver precise, well-structured explanations in **Markdown format**.\n",
    "- **Context Awareness:** Understand the query‚Äôs domain (math, reasoning, verbal, subject-specific) and ask clarifying questions if needed.\n",
    "- **Exam-Specific Knowledge:** Incorporate insights from previous exams, and suggest shortcuts or strategies for efficient problem-solving.\n",
    "- **Engagement & Support:** Maintain a friendly, motivating tone. Offer further study resources or practice exercises as applicable.\n",
    "- **Subject Coverage:** Address all areas of master‚Äôs exams (Quantitative Aptitude, Logical Reasoning, Verbal Ability, General Awareness, and Subject-Specific Topics).\n",
    "- **Follow-Up & Reinforcement:** Suggest additional practice or deeper breakdowns for complex topics. Provide insights on weak areas based on common queries.\n",
    "- **Adaptive Learning:** Tailor explanations to the user‚Äôs difficulty level. Simplify complex topics when necessary.\n",
    "- **Multi-Language Support:** Offer explanations in the user‚Äôs preferred language, leveraging Google Translate when needed.\n",
    "\"\"\"\n",
    "\n",
    "def respond_to_user(user_input , subject , image , chat_history):\n",
    "    if not subject:\n",
    "        return chat_history + [(\"Please select a subject before asking a question.\", \"\")]\n",
    "        \n",
    "    messages = [\n",
    "        {\"role\":\"system\",\"content\":system_prompt},\n",
    "    ]\n",
    "    for user , ai in chat_history:\n",
    "        messages.append({\"role\":\"user\",\"content\":user})\n",
    "        messages.append({\"role\":\"assistant\",\"content\":ai})\n",
    "\n",
    "    if user_input:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    if image:\n",
    "        messages.append({\"role\": \"user\", \"content\": {\"type\": \"image\", \"image\": image}})\n",
    "        \n",
    "    try:\n",
    "        response = ollama.chat(model=\"llama3.2\", messages=messages)\n",
    "        ai_reply = response.get(\"message\", {}).get(\"content\", \"No response received.\")\n",
    "        return chat_history + [(user_input, ai_reply)]\n",
    "    \n",
    "    except Exception as e:\n",
    "        return chat_history + [(user_input, f\" Error: {str(e)}\")]\n",
    "\n",
    "with gr.Blocks(css=\"\"\"\n",
    ":root {\n",
    "    --background-fill-primary: #121212 !important;\n",
    "    --text-primary: #E0E0E0 !important;\n",
    "}\n",
    "\n",
    "/* Headings */\n",
    ".gradio-container h1, .gradio-container h2 {\n",
    "    color: #FFFFFF !important;\n",
    "    font-weight: 900 !important;\n",
    "    text-transform: uppercase;\n",
    "    text-shadow: 2px 2px 8px rgba(255, 255, 255, 0.2);\n",
    "    letter-spacing: 1.2px;\n",
    "}\n",
    "\n",
    "/* Subheadings & Bold Text */\n",
    ".gradio-container .markdown strong {\n",
    "    color: #FFD700 !important;\n",
    "    font-weight: 800 !important;\n",
    "}\n",
    "\"\"\") as tutor_ui:\n",
    "    gr.Markdown(\"## üéì Master's AI Tutor - 24/7 Instant Doubt Solver\")\n",
    "    gr.Markdown(\"Ask doubts from **Quant, Verbal, Logical Reasoning, General Awareness** & Subject-Specific topics!\")\n",
    "\n",
    "\n",
    "    with gr.Row():\n",
    "        subject_dropdown = gr.Dropdown([\"Quantitative Aptitude\", \"Logical Reasoning\", \"Verbal Ability\", \"General Awareness\", \"Subject-Specific\"], label=\"üìö Select Subject\")\n",
    "        image_upload = gr.Image(label=\"üì∑ Upload an Image (Optional)\", type=\"pil\")\n",
    "\n",
    "    chat_history = gr.State([])\n",
    "    chatbot = gr.Chatbot(label=\"üìñ Tutor's Response\")\n",
    "    user_input = gr.Textbox(label=\"üí° Ask a question...\")\n",
    "\n",
    "    with gr.Row():\n",
    "        ask_btn = gr.Button(\"üöÄ Ask AI\")\n",
    "        clear_btn = gr.Button(\"üóëÔ∏è Clear Chat\")\n",
    "\n",
    "    ask_btn.click(respond_to_user, inputs=[user_input, subject_dropdown, image_upload, chat_history], outputs=chatbot)\n",
    "    clear_btn.click(lambda: [], outputs=chatbot)\n",
    "\n",
    "\n",
    "tutor_ui.launch( share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d26153-34f3-4aef-8d0b-cd530dd7bb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
